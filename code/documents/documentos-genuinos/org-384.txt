Semantic Textual Similarity (STS) seeks to measure the degree of semantic equivalence between two snippets of text. Similarity is ex- pressed on an ordinal scale that spans from semantic equivalence to complete unrelated- ness. Intermediate values capture specifically defined levels of partial similarity. While prior evaluations constrained themselves to just monolingual snippets of text, the 2016 shared task includes a pilot subtask on com- puting semantic similarity on cross-lingual text snippets. This yearâ€™s traditional mono- lingual subtask involves the evaluation of En- glish text snippets from the following four do- mains: Plagiarism Detection, Post-Edited Ma- chine Translations, Question-Answering and News Article Headlines. From the question- answering domain, we include both question- question and answer-answer pairs. The cross-lingual subtask provides paired Spanish- English text snippets drawn from the same sources as the English data as well as indepen- dently sampled news data. The English sub- task attracted 43 participating teams produc- ing 119 system submissions, while the cross- lingual Spanish-English pilot subtask attracted 10 teams resulting in 26 systems.