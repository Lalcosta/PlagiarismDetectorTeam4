Scientific plagiarism has become more prevalent due to technological advancements, posing a challenge in detecting lexical, syntactic, and semantic text similarities. To address this issue, a new database was created in this study, recording features that reflect various types of text similarities. The database was utilized for intelligent learning in developing a reliable plagiarism detection system based on deep learning. Different deep learning approaches, including convolution and recurrent neural network architectures, were considered, and the proposed system achieved top-ranking results in comparison to other systems on benchmark datasets. In another study, the focus was on clustering high-dimensional and sparse text document vectors using a spherical k-means algorithm. Empirical observations revealed a "fractal-like" and "self-similar" behavior in the clusters produced by the algorithm. Additionally, concept decompositions were introduced to approximate the matrix of document vectors, demonstrating close approximation errors to truncated singular value decompositions. The concept vectors generated by the algorithm were found to be localized, sparse, and tending towards orthonormality, exhibiting interesting relationships with the leading singular vectors. Furthermore, the evaluation of Semantic Textual Similarity (STS) involves measuring semantic equivalence between text snippets. The evaluation encompasses monolingual snippets and a pilot subtask for cross-lingual text snippets. Multiple domains, such as plagiarism detection, post-edited machine translations, question-answering, and news article headlines, were included in the evaluation. The participation in the English subtask was significant, with 43 teams and 119 system submissions, while the cross-lingual Spanish-English subtask attracted 10 teams and 26 systems.